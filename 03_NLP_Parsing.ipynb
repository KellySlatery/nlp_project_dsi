{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & NLP - 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelly Slatery | US-DSI-10 | 01.31.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set viewing options\n",
    "pd.set_option('display.max_columns', 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import beatles submissions (20,000)\n",
    "beatles_subs = pd.read_csv('./data/clean_beatles_subs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19961, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at shape (rows, columns)\n",
    "beatles_subs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import queen submissions (20,000)\n",
    "queen_subs = pd.read_csv('./data/clean_queen_subs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19491, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at shape (rows, columns)\n",
    "queen_subs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes\n",
    "submissions = pd.concat([beatles_subs, queen_subs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many duplicates are there?\n",
    "submissions.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>funnybunnybread2_0</td>\n",
       "      <td>-</td>\n",
       "      <td>1564754820</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>queen</td>\n",
       "      <td>How do you think John feels about Brian and Ro...</td>\n",
       "      <td>funnybunnybread2_0</td>\n",
       "      <td>How do you think John feels about Brian and Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13660</th>\n",
       "      <td>two_tits_</td>\n",
       "      <td>-</td>\n",
       "      <td>1542361942</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>queen</td>\n",
       "      <td>I've paid my dues</td>\n",
       "      <td>two_tits_</td>\n",
       "      <td>I've paid my dues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author author_flair_text  created_utc  score selftext  \\\n",
       "4504   funnybunnybread2_0                 -   1564754820      1        -   \n",
       "13660           two_tits_                 -   1542361942      1        -   \n",
       "\n",
       "      subreddit                                              title  \\\n",
       "4504      queen  How do you think John feels about Brian and Ro...   \n",
       "13660     queen                                  I've paid my dues   \n",
       "\n",
       "              author_full                                           all_text  \n",
       "4504   funnybunnybread2_0  How do you think John feels about Brian and Ro...  \n",
       "13660           two_tits_                                  I've paid my dues  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at duplicated rows\n",
    "submissions[submissions.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated rows\n",
    "submissions.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify 'subreddit' column for classification\n",
    "submissions['subreddit'] = [1 if x == 'beatles' else 0 for x in submissions['subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lanovart</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154959</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Fan art. Magnet from gypsum</td>\n",
       "      <td>Lanovart</td>\n",
       "      <td>Fan art. Magnet from gypsum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154755</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>EMI Studios, 1963.</td>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>EMI Studios, 1963.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154655</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Klein, Lennon and Ono, 1969.</td>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>Klein, Lennon and Ono, 1969.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author author_flair_text  created_utc  score selftext  subreddit  \\\n",
       "0     Lanovart                 -   1580154959      1        -          1   \n",
       "1  jackjoy1992                 -   1580154755      1        -          1   \n",
       "2  jackjoy1992                 -   1580154655      1        -          1   \n",
       "\n",
       "                          title  author_full                      all_text  \n",
       "0   Fan art. Magnet from gypsum     Lanovart   Fan art. Magnet from gypsum  \n",
       "1            EMI Studios, 1963.  jackjoy1992            EMI Studios, 1963.  \n",
       "2  Klein, Lennon and Ono, 1969.  jackjoy1992  Klein, Lennon and Ono, 1969.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19488</th>\n",
       "      <td>QueenSongoftheDay</td>\n",
       "      <td>-</td>\n",
       "      <td>1371580630</td>\n",
       "      <td>15</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>Song of the Day #17- Drowse</td>\n",
       "      <td>QueenSongoftheDay</td>\n",
       "      <td>Song of the Day #17- Drowse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19489</th>\n",
       "      <td>QueenSongoftheDay</td>\n",
       "      <td>-</td>\n",
       "      <td>1371485018</td>\n",
       "      <td>27</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>Song of the Day #16- Death on Two Legs (Dedica...</td>\n",
       "      <td>QueenSongoftheDay</td>\n",
       "      <td>Song of the Day #16- Death on Two Legs (Dedica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19490</th>\n",
       "      <td>woehoe</td>\n",
       "      <td>-</td>\n",
       "      <td>1371419736</td>\n",
       "      <td>24</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>Some of Freddie's funniest live moments</td>\n",
       "      <td>woehoe</td>\n",
       "      <td>Some of Freddie's funniest live moments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author author_flair_text  created_utc  score selftext  \\\n",
       "19488  QueenSongoftheDay                 -   1371580630     15        -   \n",
       "19489  QueenSongoftheDay                 -   1371485018     27        -   \n",
       "19490             woehoe                 -   1371419736     24        -   \n",
       "\n",
       "       subreddit                                              title  \\\n",
       "19488          0                        Song of the Day #17- Drowse   \n",
       "19489          0  Song of the Day #16- Death on Two Legs (Dedica...   \n",
       "19490          0            Some of Freddie's funniest live moments   \n",
       "\n",
       "             author_full                                           all_text  \n",
       "19488  QueenSongoftheDay                        Song of the Day #17- Drowse  \n",
       "19489  QueenSongoftheDay  Song of the Day #16- Death on Two Legs (Dedica...  \n",
       "19490             woehoe            Some of Freddie's funniest live moments  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author               object\n",
       "author_flair_text    object\n",
       "created_utc           int64\n",
       "score                 int64\n",
       "selftext             object\n",
       "subreddit             int64\n",
       "title                object\n",
       "author_full          object\n",
       "all_text             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at datatypes\n",
    "submissions.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import beatles comments (20,000)\n",
    "beatles_coms = pd.read_csv('./data/clean_beatles_coms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19983, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles_coms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import queen comments (20,000)\n",
    "queen_coms = pd.read_csv('./data/clean_queen_coms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queen_coms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes\n",
    "comments = pd.concat([beatles_coms, queen_coms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many duplicates are there?\n",
    "comments.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>funnybunnybread2_0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.564755e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>queen</td>\n",
       "      <td>How do you think John feels about Brian and Ro...</td>\n",
       "      <td>funnybunnybread2_0</td>\n",
       "      <td>How do you think John feels about Brian and Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14106</th>\n",
       "      <td>two_tits_</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.542362e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>queen</td>\n",
       "      <td>I've paid my dues</td>\n",
       "      <td>two_tits_</td>\n",
       "      <td>I've paid my dues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author author_flair_text body   created_utc  score  \\\n",
       "4942   funnybunnybread2_0                 -    -  1.564755e+09    1.0   \n",
       "14106           two_tits_                 -    -  1.542362e+09    1.0   \n",
       "\n",
       "      selftext subreddit                                              title  \\\n",
       "4942         -     queen  How do you think John feels about Brian and Ro...   \n",
       "14106        -     queen                                  I've paid my dues   \n",
       "\n",
       "              author_full                                           all_text  \n",
       "4942   funnybunnybread2_0  How do you think John feels about Brian and Ro...  \n",
       "14106           two_tits_                                  I've paid my dues  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at duplicated rows\n",
    "comments[comments.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odd that both submissions and comments data have the same duplicates, and by different authors. Assuming that since other values in the dataframes aren't the same, these two authors were probably really trying to get their point across."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated rows\n",
    "comments.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify 'subreddit' column for classification\n",
    "comments['subreddit'] = [1 if x == 'beatles' else 0 for x in comments['subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356BC</td>\n",
       "      <td>-</td>\n",
       "      <td>Sorry, I wasn't trying to sound like a dick. I...</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>356BC</td>\n",
       "      <td>Sorry, I wasn't trying to sound like a dick. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>-</td>\n",
       "      <td>Oh man to be one of those standing there, watc...</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>Oh man to be one of those standing there, watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>-</td>\n",
       "      <td>Ded from those sick beats</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>Ded from those sick beats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author author_flair_text  \\\n",
       "0                356BC                 -   \n",
       "1  EveningsAndWeekends                 -   \n",
       "2  EveningsAndWeekends                 -   \n",
       "\n",
       "                                                body   created_utc  score  \\\n",
       "0  Sorry, I wasn't trying to sound like a dick. I...  1.580156e+09    1.0   \n",
       "1  Oh man to be one of those standing there, watc...  1.580156e+09    1.0   \n",
       "2                          Ded from those sick beats  1.580156e+09    1.0   \n",
       "\n",
       "  selftext  subreddit title          author_full  \\\n",
       "0        -          1     -                356BC   \n",
       "1        -          1     -  EveningsAndWeekends   \n",
       "2        -          1     -  EveningsAndWeekends   \n",
       "\n",
       "                                            all_text  \n",
       "0  Sorry, I wasn't trying to sound like a dick. I...  \n",
       "1  Oh man to be one of those standing there, watc...  \n",
       "2                          Ded from those sick beats  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Kastain</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.392904e+09</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>John Deacon with an awesome hat in the music v...</td>\n",
       "      <td>Kastain</td>\n",
       "      <td>John Deacon with an awesome hat in the music v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Pinkiepoi</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.392852e+09</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh Freddy, you pervert...</td>\n",
       "      <td>Pinkiepoi</td>\n",
       "      <td>Oh Freddy, you pervert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Mick_Wyld</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.392825e+09</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>The A.V. CLUB breaks down The Game</td>\n",
       "      <td>Mick_Wyld</td>\n",
       "      <td>The A.V. CLUB breaks down The Game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author author_flair_text body   created_utc  score selftext  \\\n",
       "19997    Kastain                 -    -  1.392904e+09   18.0        -   \n",
       "19998  Pinkiepoi                 -    -  1.392852e+09   12.0        -   \n",
       "19999  Mick_Wyld                 -    -  1.392825e+09   18.0        -   \n",
       "\n",
       "       subreddit                                              title  \\\n",
       "19997          0  John Deacon with an awesome hat in the music v...   \n",
       "19998          0                          Oh Freddy, you pervert...   \n",
       "19999          0                 The A.V. CLUB breaks down The Game   \n",
       "\n",
       "      author_full                                           all_text  \n",
       "19997     Kastain  John Deacon with an awesome hat in the music v...  \n",
       "19998   Pinkiepoi                          Oh Freddy, you pervert...  \n",
       "19999   Mick_Wyld                 The A.V. CLUB breaks down The Game  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                object\n",
       "author_flair_text     object\n",
       "body                  object\n",
       "created_utc          float64\n",
       "score                float64\n",
       "selftext              object\n",
       "subreddit              int64\n",
       "title                 object\n",
       "author_full           object\n",
       "all_text              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at datatypes\n",
    "comments.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of columns for submissions for primary NLP parsing (no author data)\n",
    "cols_sub_nlp = ['selftext', 'title', 'all_text']\n",
    "\n",
    "# Make list of columns for comments for primary NLP parsing (no author data)\n",
    "cols_com_nlp = ['body', 'selftext', 'title', 'all_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean text data (remove whitespace, \n",
    "# keep only alphabet characters & make lowercase)\n",
    "\n",
    "def tokenize_data(data, col_list):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for col in col_list:\n",
    "        tokenized_items = [tokenizer.tokenize(item.lower()) for item in data[col]]\n",
    "        data[f'tokenized_{col}'] = tokenized_items\n",
    "    return data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "      <th>tokenized_selftext</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>tokenized_all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lanovart</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154959</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Fan art. Magnet from gypsum</td>\n",
       "      <td>Lanovart</td>\n",
       "      <td>Fan art. Magnet from gypsum</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154755</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>EMI Studios, 1963.</td>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>EMI Studios, 1963.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[emi, studios, 1963]</td>\n",
       "      <td>[emi, studios, 1963]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154655</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Klein, Lennon and Ono, 1969.</td>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>Klein, Lennon and Ono, 1969.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author author_flair_text  created_utc  score selftext  subreddit  \\\n",
       "0     Lanovart                 -   1580154959      1        -          1   \n",
       "1  jackjoy1992                 -   1580154755      1        -          1   \n",
       "2  jackjoy1992                 -   1580154655      1        -          1   \n",
       "\n",
       "                          title  author_full                      all_text  \\\n",
       "0   Fan art. Magnet from gypsum     Lanovart   Fan art. Magnet from gypsum   \n",
       "1            EMI Studios, 1963.  jackjoy1992            EMI Studios, 1963.   \n",
       "2  Klein, Lennon and Ono, 1969.  jackjoy1992  Klein, Lennon and Ono, 1969.   \n",
       "\n",
       "  tokenized_selftext                   tokenized_title  \\\n",
       "0                 []  [fan, art, magnet, from, gypsum]   \n",
       "1                 []              [emi, studios, 1963]   \n",
       "2                 []   [klein, lennon, and, ono, 1969]   \n",
       "\n",
       "                 tokenized_all_text  \n",
       "0  [fan, art, magnet, from, gypsum]  \n",
       "1              [emi, studios, 1963]  \n",
       "2   [klein, lennon, and, ono, 1969]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize submissions text data \n",
    "submissions = tokenize_data(submissions, cols_sub_nlp)\n",
    "submissions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "      <th>tokenized_selftext</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>tokenized_all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356BC</td>\n",
       "      <td>-</td>\n",
       "      <td>Sorry, I wasn't trying to sound like a dick. I...</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>356BC</td>\n",
       "      <td>Sorry, I wasn't trying to sound like a dick. I...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sorry, i, wasn, t, trying, to, sound, like, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>-</td>\n",
       "      <td>Oh man to be one of those standing there, watc...</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>Oh man to be one of those standing there, watc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[oh, man, to, be, one, of, those, standing, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>-</td>\n",
       "      <td>Ded from those sick beats</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>Ded from those sick beats</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ded, from, those, sick, beats]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author author_flair_text  \\\n",
       "0                356BC                 -   \n",
       "1  EveningsAndWeekends                 -   \n",
       "2  EveningsAndWeekends                 -   \n",
       "\n",
       "                                                body   created_utc  score  \\\n",
       "0  Sorry, I wasn't trying to sound like a dick. I...  1.580156e+09    1.0   \n",
       "1  Oh man to be one of those standing there, watc...  1.580156e+09    1.0   \n",
       "2                          Ded from those sick beats  1.580156e+09    1.0   \n",
       "\n",
       "  selftext  subreddit title          author_full  \\\n",
       "0        -          1     -                356BC   \n",
       "1        -          1     -  EveningsAndWeekends   \n",
       "2        -          1     -  EveningsAndWeekends   \n",
       "\n",
       "                                            all_text tokenized_selftext  \\\n",
       "0  Sorry, I wasn't trying to sound like a dick. I...                 []   \n",
       "1  Oh man to be one of those standing there, watc...                 []   \n",
       "2                          Ded from those sick beats                 []   \n",
       "\n",
       "  tokenized_title                                 tokenized_all_text  \n",
       "0              []  [sorry, i, wasn, t, trying, to, sound, like, a...  \n",
       "1              []  [oh, man, to, be, one, of, those, standing, th...  \n",
       "2              []                    [ded, from, those, sick, beats]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize comments text data \n",
    "comments = tokenize_data(comments, cols_sub_nlp)\n",
    "comments.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of columns for submissions for primary NLP parsing (no author data)\n",
    "tok_cols_sub_nlp = ['tokenized_selftext', 'tokenized_title', 'tokenized_all_text']\n",
    "\n",
    "# Make list of columns for comments for primary NLP parsing (no author data)\n",
    "tok_cols_com_nlp = ['tokenized_body', 'tokenized_selftext', 'tokenized_title', 'tokenized_all_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to lemmatize text data \n",
    "\n",
    "def lemmatize_data(data, col_list):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for col in col_list:\n",
    "        lemmed_items = []\n",
    "        for row in data[col]:\n",
    "            lemmed_row = [lemmatizer.lemmatize(word) for word in row]\n",
    "            lemmed_items.append(lemmed_row)\n",
    "        data[f'lemmatized_{col}'] = lemmed_items\n",
    "    return data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize submissions text data \n",
    "submissions = lemmatize_data(submissions, tok_cols_sub_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "      <th>tokenized_selftext</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>tokenized_all_text</th>\n",
       "      <th>lemmatized_tokenized_selftext</th>\n",
       "      <th>lemmatized_tokenized_title</th>\n",
       "      <th>lemmatized_tokenized_all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lanovart</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154959</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Fan art. Magnet from gypsum</td>\n",
       "      <td>Lanovart</td>\n",
       "      <td>Fan art. Magnet from gypsum</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154755</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>EMI Studios, 1963.</td>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>EMI Studios, 1963.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[emi, studios, 1963]</td>\n",
       "      <td>[emi, studios, 1963]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[emi, studio, 1963]</td>\n",
       "      <td>[emi, studio, 1963]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154655</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Klein, Lennon and Ono, 1969.</td>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>Klein, Lennon and Ono, 1969.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author author_flair_text  created_utc  score selftext  subreddit  \\\n",
       "0     Lanovart                 -   1580154959      1        -          1   \n",
       "1  jackjoy1992                 -   1580154755      1        -          1   \n",
       "2  jackjoy1992                 -   1580154655      1        -          1   \n",
       "\n",
       "                          title  author_full                      all_text  \\\n",
       "0   Fan art. Magnet from gypsum     Lanovart   Fan art. Magnet from gypsum   \n",
       "1            EMI Studios, 1963.  jackjoy1992            EMI Studios, 1963.   \n",
       "2  Klein, Lennon and Ono, 1969.  jackjoy1992  Klein, Lennon and Ono, 1969.   \n",
       "\n",
       "  tokenized_selftext                   tokenized_title  \\\n",
       "0                 []  [fan, art, magnet, from, gypsum]   \n",
       "1                 []              [emi, studios, 1963]   \n",
       "2                 []   [klein, lennon, and, ono, 1969]   \n",
       "\n",
       "                 tokenized_all_text lemmatized_tokenized_selftext  \\\n",
       "0  [fan, art, magnet, from, gypsum]                            []   \n",
       "1              [emi, studios, 1963]                            []   \n",
       "2   [klein, lennon, and, ono, 1969]                            []   \n",
       "\n",
       "         lemmatized_tokenized_title     lemmatized_tokenized_all_text  \n",
       "0  [fan, art, magnet, from, gypsum]  [fan, art, magnet, from, gypsum]  \n",
       "1               [emi, studio, 1963]               [emi, studio, 1963]  \n",
       "2   [klein, lennon, and, ono, 1969]   [klein, lennon, and, ono, 1969]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize comments text data \n",
    "comments = lemmatize_data(comments, tok_cols_sub_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "      <th>tokenized_selftext</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>tokenized_all_text</th>\n",
       "      <th>lemmatized_tokenized_selftext</th>\n",
       "      <th>lemmatized_tokenized_title</th>\n",
       "      <th>lemmatized_tokenized_all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356BC</td>\n",
       "      <td>-</td>\n",
       "      <td>Sorry, I wasn't trying to sound like a dick. I...</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>356BC</td>\n",
       "      <td>Sorry, I wasn't trying to sound like a dick. I...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sorry, i, wasn, t, trying, to, sound, like, a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sorry, i, wasn, t, trying, to, sound, like, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>-</td>\n",
       "      <td>Oh man to be one of those standing there, watc...</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>Oh man to be one of those standing there, watc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[oh, man, to, be, one, of, those, standing, th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[oh, man, to, be, one, of, those, standing, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>-</td>\n",
       "      <td>Ded from those sick beats</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>Ded from those sick beats</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ded, from, those, sick, beats]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ded, from, those, sick, beat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author author_flair_text  \\\n",
       "0                356BC                 -   \n",
       "1  EveningsAndWeekends                 -   \n",
       "2  EveningsAndWeekends                 -   \n",
       "\n",
       "                                                body   created_utc  score  \\\n",
       "0  Sorry, I wasn't trying to sound like a dick. I...  1.580156e+09    1.0   \n",
       "1  Oh man to be one of those standing there, watc...  1.580156e+09    1.0   \n",
       "2                          Ded from those sick beats  1.580156e+09    1.0   \n",
       "\n",
       "  selftext  subreddit title          author_full  \\\n",
       "0        -          1     -                356BC   \n",
       "1        -          1     -  EveningsAndWeekends   \n",
       "2        -          1     -  EveningsAndWeekends   \n",
       "\n",
       "                                            all_text tokenized_selftext  \\\n",
       "0  Sorry, I wasn't trying to sound like a dick. I...                 []   \n",
       "1  Oh man to be one of those standing there, watc...                 []   \n",
       "2                          Ded from those sick beats                 []   \n",
       "\n",
       "  tokenized_title                                 tokenized_all_text  \\\n",
       "0              []  [sorry, i, wasn, t, trying, to, sound, like, a...   \n",
       "1              []  [oh, man, to, be, one, of, those, standing, th...   \n",
       "2              []                    [ded, from, those, sick, beats]   \n",
       "\n",
       "  lemmatized_tokenized_selftext lemmatized_tokenized_title  \\\n",
       "0                            []                         []   \n",
       "1                            []                         []   \n",
       "2                            []                         []   \n",
       "\n",
       "                       lemmatized_tokenized_all_text  \n",
       "0  [sorry, i, wasn, t, trying, to, sound, like, a...  \n",
       "1  [oh, man, to, be, one, of, those, standing, th...  \n",
       "2                     [ded, from, those, sick, beat]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmatize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to stemmatize text data \n",
    "\n",
    "def stemmatize_data(data, col_list):\n",
    "    p_stemmer = PorterStemmer()\n",
    "    for col in col_list:\n",
    "        stemmed_items = []\n",
    "        for row in data[col]:\n",
    "            stemmed_row = [p_stemmer.stem(word) for word in row]\n",
    "            stemmed_items.append(stemmed_row)\n",
    "        data[f'stemmatized_{col}'] = stemmed_items\n",
    "    return data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmatize submissions text data \n",
    "submissions = stemmatize_data(submissions, tok_cols_sub_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "      <th>tokenized_selftext</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>tokenized_all_text</th>\n",
       "      <th>lemmatized_tokenized_selftext</th>\n",
       "      <th>lemmatized_tokenized_title</th>\n",
       "      <th>lemmatized_tokenized_all_text</th>\n",
       "      <th>stemmatized_tokenized_selftext</th>\n",
       "      <th>stemmatized_tokenized_title</th>\n",
       "      <th>stemmatized_tokenized_all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lanovart</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154959</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Fan art. Magnet from gypsum</td>\n",
       "      <td>Lanovart</td>\n",
       "      <td>Fan art. Magnet from gypsum</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "      <td>[fan, art, magnet, from, gypsum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154755</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>EMI Studios, 1963.</td>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>EMI Studios, 1963.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[emi, studios, 1963]</td>\n",
       "      <td>[emi, studios, 1963]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[emi, studio, 1963]</td>\n",
       "      <td>[emi, studio, 1963]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[emi, studio, 1963]</td>\n",
       "      <td>[emi, studio, 1963]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>-</td>\n",
       "      <td>1580154655</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Klein, Lennon and Ono, 1969.</td>\n",
       "      <td>jackjoy1992</td>\n",
       "      <td>Klein, Lennon and Ono, 1969.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "      <td>[klein, lennon, and, ono, 1969]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author author_flair_text  created_utc  score selftext  subreddit  \\\n",
       "0     Lanovart                 -   1580154959      1        -          1   \n",
       "1  jackjoy1992                 -   1580154755      1        -          1   \n",
       "2  jackjoy1992                 -   1580154655      1        -          1   \n",
       "\n",
       "                          title  author_full                      all_text  \\\n",
       "0   Fan art. Magnet from gypsum     Lanovart   Fan art. Magnet from gypsum   \n",
       "1            EMI Studios, 1963.  jackjoy1992            EMI Studios, 1963.   \n",
       "2  Klein, Lennon and Ono, 1969.  jackjoy1992  Klein, Lennon and Ono, 1969.   \n",
       "\n",
       "  tokenized_selftext                   tokenized_title  \\\n",
       "0                 []  [fan, art, magnet, from, gypsum]   \n",
       "1                 []              [emi, studios, 1963]   \n",
       "2                 []   [klein, lennon, and, ono, 1969]   \n",
       "\n",
       "                 tokenized_all_text lemmatized_tokenized_selftext  \\\n",
       "0  [fan, art, magnet, from, gypsum]                            []   \n",
       "1              [emi, studios, 1963]                            []   \n",
       "2   [klein, lennon, and, ono, 1969]                            []   \n",
       "\n",
       "         lemmatized_tokenized_title     lemmatized_tokenized_all_text  \\\n",
       "0  [fan, art, magnet, from, gypsum]  [fan, art, magnet, from, gypsum]   \n",
       "1               [emi, studio, 1963]               [emi, studio, 1963]   \n",
       "2   [klein, lennon, and, ono, 1969]   [klein, lennon, and, ono, 1969]   \n",
       "\n",
       "  stemmatized_tokenized_selftext       stemmatized_tokenized_title  \\\n",
       "0                             []  [fan, art, magnet, from, gypsum]   \n",
       "1                             []               [emi, studio, 1963]   \n",
       "2                             []   [klein, lennon, and, ono, 1969]   \n",
       "\n",
       "     stemmatized_tokenized_all_text  \n",
       "0  [fan, art, magnet, from, gypsum]  \n",
       "1               [emi, studio, 1963]  \n",
       "2   [klein, lennon, and, ono, 1969]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmatize comments text data \n",
    "comments = stemmatize_data(comments, tok_cols_sub_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author_full</th>\n",
       "      <th>all_text</th>\n",
       "      <th>tokenized_selftext</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>tokenized_all_text</th>\n",
       "      <th>lemmatized_tokenized_selftext</th>\n",
       "      <th>lemmatized_tokenized_title</th>\n",
       "      <th>lemmatized_tokenized_all_text</th>\n",
       "      <th>stemmatized_tokenized_selftext</th>\n",
       "      <th>stemmatized_tokenized_title</th>\n",
       "      <th>stemmatized_tokenized_all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356BC</td>\n",
       "      <td>-</td>\n",
       "      <td>Sorry, I wasn't trying to sound like a dick. I...</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>356BC</td>\n",
       "      <td>Sorry, I wasn't trying to sound like a dick. I...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sorry, i, wasn, t, trying, to, sound, like, a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sorry, i, wasn, t, trying, to, sound, like, a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sorri, i, wasn, t, tri, to, sound, like, a, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>-</td>\n",
       "      <td>Oh man to be one of those standing there, watc...</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>Oh man to be one of those standing there, watc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[oh, man, to, be, one, of, those, standing, th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[oh, man, to, be, one, of, those, standing, th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[oh, man, to, be, one, of, those, stand, there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>-</td>\n",
       "      <td>Ded from those sick beats</td>\n",
       "      <td>1.580156e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>EveningsAndWeekends</td>\n",
       "      <td>Ded from those sick beats</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ded, from, those, sick, beats]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ded, from, those, sick, beat]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ded, from, those, sick, beat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author author_flair_text  \\\n",
       "0                356BC                 -   \n",
       "1  EveningsAndWeekends                 -   \n",
       "2  EveningsAndWeekends                 -   \n",
       "\n",
       "                                                body   created_utc  score  \\\n",
       "0  Sorry, I wasn't trying to sound like a dick. I...  1.580156e+09    1.0   \n",
       "1  Oh man to be one of those standing there, watc...  1.580156e+09    1.0   \n",
       "2                          Ded from those sick beats  1.580156e+09    1.0   \n",
       "\n",
       "  selftext  subreddit title          author_full  \\\n",
       "0        -          1     -                356BC   \n",
       "1        -          1     -  EveningsAndWeekends   \n",
       "2        -          1     -  EveningsAndWeekends   \n",
       "\n",
       "                                            all_text tokenized_selftext  \\\n",
       "0  Sorry, I wasn't trying to sound like a dick. I...                 []   \n",
       "1  Oh man to be one of those standing there, watc...                 []   \n",
       "2                          Ded from those sick beats                 []   \n",
       "\n",
       "  tokenized_title                                 tokenized_all_text  \\\n",
       "0              []  [sorry, i, wasn, t, trying, to, sound, like, a...   \n",
       "1              []  [oh, man, to, be, one, of, those, standing, th...   \n",
       "2              []                    [ded, from, those, sick, beats]   \n",
       "\n",
       "  lemmatized_tokenized_selftext lemmatized_tokenized_title  \\\n",
       "0                            []                         []   \n",
       "1                            []                         []   \n",
       "2                            []                         []   \n",
       "\n",
       "                       lemmatized_tokenized_all_text  \\\n",
       "0  [sorry, i, wasn, t, trying, to, sound, like, a...   \n",
       "1  [oh, man, to, be, one, of, those, standing, th...   \n",
       "2                     [ded, from, those, sick, beat]   \n",
       "\n",
       "  stemmatized_tokenized_selftext stemmatized_tokenized_title  \\\n",
       "0                             []                          []   \n",
       "1                             []                          []   \n",
       "2                             []                          []   \n",
       "\n",
       "                      stemmatized_tokenized_all_text  \n",
       "0  [sorri, i, wasn, t, tri, to, sound, like, a, d...  \n",
       "1  [oh, man, to, be, one, of, those, stand, there...  \n",
       "2                     [ded, from, those, sick, beat]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through further analysis, found strings with high frequencies but low importance to interpretation. Remove strings or rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all instances of 'favourite' to 'favorite'\n",
    "submissions['all_text'] = [row.replace('favourite', 'favorite') for row in submissions['all_text']]\n",
    "\n",
    "# Remove all strings marking websites or other formatting\n",
    "for word in [\"www.\", \"https\", \".com\", '#x200B', '&amp']:\n",
    "    submissions['all_text'] = [row.replace(word, '') for row in submissions['all_text']]\n",
    "\n",
    "# Remove all rows containing 'ufc' because they look like ads\n",
    "indices_to_drop = []\n",
    "\n",
    "for index in submissions['all_text'].index:\n",
    "    if 'ufc' in submissions.loc[index, 'all_text']:\n",
    "        indices_to_drop.append(index)\n",
    "        \n",
    "submissions.drop(submissions.index[indices_to_drop], axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all instances of 'favourite' to 'favorite' and drop unrelated words\n",
    "comments['all_text'] = [row.replace('favourite', 'favorite') for row in comments['all_text']]\n",
    "\n",
    "# Remove all strings marking websites or other formatting\n",
    "for word in [\"www.\", \"https\", \".com\", '#x200B', '&amp']:\n",
    "    comments['all_text'] = [row.replace(word, '') for row in comments['all_text']]\n",
    "\n",
    "# Remove all rows containing 'ufc'\n",
    "indices_to_drop = []\n",
    "\n",
    "for index in comments['all_text'].index:\n",
    "    if 'ufc' in comments.loc[index, 'all_text']:\n",
    "        indices_to_drop.append(index)\n",
    "        \n",
    "comments.drop(comments.index[indices_to_drop], axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export parsable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export submissions data to csv\n",
    "submissions.to_csv('./data/submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comments data to csv\n",
    "comments.to_csv('./data/comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to add a dictionary for each row\n",
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the list with name, data type, and modifications for all columns\n",
    "for col in submissions.columns:\n",
    "    this = {}\n",
    "    this['Column Name'] = col\n",
    "    this['Data Type'] = submissions[col].dtype\n",
    "    this['Modifications'] = 'None'\n",
    "    if 'tokenized' in col:\n",
    "        this['Modifications'] = 'Text data: tokenized with regular expression'\n",
    "    if 'lemmatized' in col:\n",
    "        this['Modifications'] = this['Modifications'] + ', lemmatized with WordNetLemmatizer()'\n",
    "    if 'stemmatized' in col:\n",
    "        this['Modifications'] = this['Modifications'] + ', stemmatized with PorterStemmer()'\n",
    "    if col == 'subreddit':\n",
    "        this['Modifications'] = 'Binarized'\n",
    "    if col == 'selftext' or col == 'title':\n",
    "        this['Modifications'] = \"Nulls replaced with '-'\"\n",
    "    data_list.append(this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Modifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>author</td>\n",
       "      <td>object</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>author_flair_text</td>\n",
       "      <td>object</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>created_utc</td>\n",
       "      <td>int64</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>score</td>\n",
       "      <td>int64</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>selftext</td>\n",
       "      <td>object</td>\n",
       "      <td>Nulls replaced with '-'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column Name Data Type            Modifications\n",
       "0             author    object                     None\n",
       "1  author_flair_text    object                     None\n",
       "2        created_utc     int64                     None\n",
       "3              score     int64                     None\n",
       "4           selftext    object  Nulls replaced with '-'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform dictionary into dataframe\n",
    "data_df = pd.DataFrame(data_list)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'Description' column\n",
    "data_df['Description'] = ['Author of post/submission', \n",
    "                          'Non-ascii parts of author username', \n",
    "                          'Time post was created in UTC', \n",
    "                          'Aggregate sum of upvotes and downvotes (no negatives)', \n",
    "                          'Body of post/submission', \n",
    "                          'Subreddit to which the post/submission belongs (1=Beatles, 0=Queen)', \n",
    "                          'Title of post/submission', \n",
    "                          \"Combined: 'author' and 'author_flair_text'\", \n",
    "                          \"Combined: 'selftext' and 'title'\", \n",
    "                          \"Tokenized 'selftext'\", \n",
    "                          \"Tokenized 'title'\", \n",
    "                          \"Tokenized 'all_text'\", \n",
    "                          \"Lemmatized 'tokenized_selftext'\", \n",
    "                          \"Lemmatized 'tokenized_title'\", \n",
    "                          \"Lemmatized 'tokenized_all_text'\",\n",
    "                          \"Stemmatized 'tokenized_selftext'\", \n",
    "                          \"Stemmatized 'tokenized_title'\", \n",
    "                          \"Stemmatized 'tokenized_all_text'\"\n",
    "                         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data dictionary\n",
    "data_df.to_csv('./data/data_dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
